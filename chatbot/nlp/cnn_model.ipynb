{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnopwBvwrRw2s2tnMoqnZ+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh_fINm2kNxg"
      },
      "source": [
        "CNN(Convolutional Neural Network, 합성곱 신경망) \n",
        ": 딥러닝 모델 (ex. 이미지/자연어 분류)\n",
        "1. 합성곱(convolution) : filter = mask = window = kernel 로 불리는 특정 크기의 행렬을 이미지 or 문장 데이터 행렬에 슬라이딩하면서 곱하고 더하는 연산.\n",
        "  * stride : filter 위치를 몇 칸 이동할지 결정하는 값 \n",
        "  * 슬라이딩 : filter가 이미지 데이터 행렬 위를 상하좌우로 이동하는 동작\n",
        "  * filter가 더 이상 슬라이딩 할 수 없을 때까지 반복\n",
        "  * 특징맵(feature map) : 최종 결과 / 합성곱 연산을 거칠 때마다 작아진다. -> 방지 : padding 사용\n",
        "  * padding : 출력 크기 조정 / 0으로 채움\n",
        "\n",
        "\n",
        "2. 풀링 연산 : 특징맵의 크기 줄임, 주요한 특징 추출\n",
        "  - 최대 풀링(max pooling)多 / 평균 풀링(average pooling)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_8PJ1Nxjk_W",
        "outputId": "37eb93e2-f85d-47fe-eb49-cc7966934861"
      },
      "source": [
        "# To Do! Q(질문)를 label(감정)별로 분류 (cf. A(답변) 사용 X)\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
        "\n",
        "train_file = './data/chatbot_data.csv'\n",
        "data = pd.read_csv(train_file, delimiter=',')\n",
        "print(data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             Q                         A  label\n",
            "0                       12시 땡!                하루가 또 가네요.      0\n",
            "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
            "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
            "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
            "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
            "...                        ...                       ...    ...\n",
            "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
            "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
            "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
            "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
            "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
            "\n",
            "[11823 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxcIZySxs7u8",
        "outputId": "e065e900-d72c-441c-b75c-a09ed3e35c3c"
      },
      "source": [
        "features = data['Q'].tolist()\n",
        "labels = data['label'].tolist()\n",
        "\n",
        "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
        "print(corpus[:5])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['12시', '땡'], ['1지망', '학교', '떨어졌어'], ['3박4일', '놀러가고', '싶다'], ['3박4일', '정도', '놀러가고', '싶다'], ['ppl', '심하네']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4OA_G0BfY28",
        "outputId": "7154c3f3-3d84-4201-cc86-4304f98a9008"
      },
      "source": [
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "print(sequences[:5])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4646, 4647], [4648, 343, 448], [2580, 803, 11], [2580, 804, 803, 11], [4649, 2581]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE0H9DDEf8rG"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "# print(word_index)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTrwfNOAkisV",
        "outputId": "0a18e849-c535-4d6a-e4dc-c107f90155c0"
      },
      "source": [
        "# 전체 벡터 크기를 동일하게 맞춰야 함\n",
        "MAX_SEQ_LEN = 15 \n",
        "padded_seqs = preprocessing.sequence.pad_sequences(sequences, \n",
        "                                                   maxlen=MAX_SEQ_LEN, # 시퀀스의 최대 길이\n",
        "                                                   padding='post') # 빈 공간을 0으로 채우는 작업\n",
        "print(padded_seqs)                                                   "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4646  4647     0 ...     0     0     0]\n",
            " [ 4648   343   448 ...     0     0     0]\n",
            " [ 2580   803    11 ...     0     0     0]\n",
            " ...\n",
            " [13395  2517    89 ...     0     0     0]\n",
            " [  147    46    91 ...     0     0     0]\n",
            " [  555 13398     0 ...     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w52m2-aitXHF",
        "outputId": "35edb1e5-07e2-4afd-b221-4bb7cb230d8b"
      },
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
        "ds = ds.shuffle(len(features))\n",
        "\n",
        "# train:valid:test = 7:2:1\n",
        "train_size = int(len(padded_seqs) * 0.7)\n",
        "val_size = int(len(padded_seqs) * 0.2)\n",
        "test_size = int(len(padded_seqs) * 0.1)\n",
        "\n",
        "train_ds = ds.take(train_size).batch(20)\n",
        "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
        "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
        "\n",
        "# 하이퍼파라미터\n",
        "dropout_prob = 0.5\n",
        "EMB_SIZE = 128 # 임베딩 결과로 나올 밀집 벡터 크기\n",
        "EPOCH = 5\n",
        "VOCAB_SIZE = len(word_index) + 1 # 전체 단어 수\n",
        "\n",
        "# 단어 임베딩\n",
        "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
        "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
        "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer) # 오버피팅(과적합)에 대비\n",
        "\n",
        "# 특징 추출 (특징맵)\n",
        "# 합성곱 연산\n",
        "conv1 = Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=3,\n",
        "    padding='valid',\n",
        "    activation=tf.nn.relu)(dropout_emb)\n",
        "pool1 = GlobalMaxPool1D()(conv1) # 최대 풀링 연산\n",
        "\n",
        "conv2 = Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=4,\n",
        "    padding='valid',\n",
        "    activation=tf.nn.relu)(dropout_emb)\n",
        "pool2 = GlobalMaxPool1D()(conv2)\n",
        "\n",
        "conv3 = Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=5,\n",
        "    padding='valid',\n",
        "    activation=tf.nn.relu)(dropout_emb)\n",
        "pool3 = GlobalMaxPool1D()(conv3)\n",
        "\n",
        "concat = concatenate([pool1, pool2, pool3])\n",
        "\n",
        "# 완전 연결 계층\n",
        "hidden = Dense(128, # 출력 노드 수\n",
        "               activation=tf.nn.relu)(concat)\n",
        "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
        "\n",
        "logits = Dense(3, # 3가지 클래스로 감정 분류 해야 하기 때문에\n",
        "               name='logits')(dropout_hidden)\n",
        "\n",
        "# 감정 클래스별 확률 \n",
        "predictions = Dense(3, activation=tf.nn.softmax)(logits)\n",
        "\n",
        "# CNN 모델 생성\n",
        "model = Model(inputs=input_layer, outputs=predictions)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # 손실 함수\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH\n",
        "          , verbose=1) # 진행 과정 상세히 (<-> 0:생략)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "414/414 [==============================] - 17s 38ms/step - loss: 0.8716 - accuracy: 0.5936 - val_loss: 0.5182 - val_accuracy: 0.8071\n",
            "Epoch 2/5\n",
            "414/414 [==============================] - 15s 36ms/step - loss: 0.5058 - accuracy: 0.8143 - val_loss: 0.2778 - val_accuracy: 0.9137\n",
            "Epoch 3/5\n",
            "414/414 [==============================] - 15s 36ms/step - loss: 0.3044 - accuracy: 0.9004 - val_loss: 0.1440 - val_accuracy: 0.9509\n",
            "Epoch 4/5\n",
            "414/414 [==============================] - 15s 36ms/step - loss: 0.1936 - accuracy: 0.9372 - val_loss: 0.1025 - val_accuracy: 0.9712\n",
            "Epoch 5/5\n",
            "414/414 [==============================] - 15s 35ms/step - loss: 0.1306 - accuracy: 0.9606 - val_loss: 0.0617 - val_accuracy: 0.9797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a9efa5a10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMsYi08S0NVB",
        "outputId": "ac16dff0-9879-447c-a192-3d5f1177981d"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFdX9E4r8Zfr",
        "outputId": "371802b4-d218-4ee2-c79e-de06a283eb50"
      },
      "source": [
        "print('Accuracy: %f' % (accuracy * 100))\n",
        "print('loss: %f' % (loss))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.715735\n",
            "loss: 0.083776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1b8tMkI1H0Q"
      },
      "source": [
        "model.save('cnn_model.h5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZIEjv43rVcv",
        "outputId": "4e3ae706-3de3-4d82-93fe-d522a43aba89"
      },
      "source": [
        "test_ds = ds.take(2000).batch(20)\n",
        "\n",
        "model = load_model('cnn_model.h5')\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 15, 128)      1715072     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 15, 128)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 13, 128)      49280       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 12, 128)      65664       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 11, 128)      82048       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 128)          0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 384)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          49280       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "logits (Dense)                  (None, 3)            387         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3)            12          logits[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,961,743\n",
            "Trainable params: 1,961,743\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE85mJIsrjdf",
        "outputId": "c3324e06-1650-40ae-fdb8-754d172c8d4d"
      },
      "source": [
        "model.evaluate(test_ds, verbose=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 - 1s - loss: 0.0751 - accuracy: 0.9800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07508394122123718, 0.9800000190734863]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe2Ynlxlr1qe",
        "outputId": "9eb3b709-28eb-40ca-eec8-3dcde2dece0c"
      },
      "source": [
        "print('단어 시퀀스 :', corpus[10212])\n",
        "print('단어 인덱스 시퀀스 :', padded_seqs[10212])\n",
        "print('문장 분류(정답):', labels[10212])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 시퀀스 : ['썸', '타는', '여자가', '남사친', '만나러', '간다는데', '뭐라', '해']\n",
            "단어 인덱스 시퀀스 : [   13    61   127  4320  1333 12162   856    31     0     0     0     0\n",
            "     0     0     0]\n",
            "문장 분류(정답): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in16PQdTtowg",
        "outputId": "afac3c9a-ff25-410f-8f32-951d1f1cfd3b"
      },
      "source": [
        "picks = [10212]\n",
        "predict = model.predict(padded_seqs[picks])\n",
        "predict_class = tf.math.argmax(predict, axis=1)\n",
        "print('감정 예측 점수 :', predict)\n",
        "print('감정 예측 클래스 :', predict_class.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "감정 예측 점수 : [[3.7599688e-07 5.2813357e-07 9.9999905e-01]]\n",
            "감정 예측 클래스 : [2]\n"
          ]
        }
      ]
    }
  ]
}