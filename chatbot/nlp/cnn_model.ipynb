{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKuHrfLsF9llNWuskmIC7O"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh_fINm2kNxg"
      },
      "source": [
        "CNN(Convolutional Neural Network, 합성곱 신경망) \n",
        ": 딥러닝 모델 (ex. 이미지/자연어 분류)\n",
        "\n",
        "1.합성곱(convolution) : filter = mask = window = kernel 로 불리는 특정 크기의 행렬을 이미지 or 문장 데이터 행렬에 슬라이딩하면서 곱하고 더하는 연산.\n",
        "  * stride : filter 위치를 몇 칸 이동할지 결정하는 값 \n",
        "  * 슬라이딩 : filter가 이미지 데이터 행렬 위를 상하좌우로 이동하는 동작\n",
        "  * filter가 더 이상 슬라이딩 할 수 없을 때까지 반복\n",
        "  * 특징맵(feature map) : 최종 결과 / 합성곱 연산을 거칠 때마다 작아진다. -> 방지 : padding 사용\n",
        "  * padding : 출력 크기 조정 / 0으로 채움\n",
        "\n",
        "\n",
        "2.풀링 연산 : 특징맵의 크기 줄임, 주요한 특징 추출\n",
        "  - 최대 풀링(max pooling)多 / 평균 풀링(average pooling)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_8PJ1Nxjk_W",
        "outputId": "5a2c5c02-fd0e-4217-e045-4a0d57eb6f5e"
      },
      "source": [
        "# To Do! Q(질문)를 label(감정)별로 분류 (cf. A(답변) 사용 X)\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
        "\n",
        "train_file = './data/chatbot_data.csv'\n",
        "data = pd.read_csv(train_file, delimiter=',')\n",
        "print(data)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             Q                         A  label\n",
            "0                       12시 땡!                하루가 또 가네요.      0\n",
            "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
            "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
            "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
            "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
            "...                        ...                       ...    ...\n",
            "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
            "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
            "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
            "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
            "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
            "\n",
            "[11823 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxcIZySxs7u8",
        "outputId": "6a7df98f-0258-4825-dbe5-2f2a82cac8e5"
      },
      "source": [
        "features = data['Q'].tolist()\n",
        "labels = data['label'].tolist()\n",
        "\n",
        "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
        "print(corpus[:5])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['12시', '땡'], ['1지망', '학교', '떨어졌어'], ['3박4일', '놀러가고', '싶다'], ['3박4일', '정도', '놀러가고', '싶다'], ['ppl', '심하네']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4OA_G0BfY28",
        "outputId": "2efc1ed7-e01d-4270-97f1-d9db6f0e2a62"
      },
      "source": [
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "print(sequences[:5])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4646, 4647], [4648, 343, 448], [2580, 803, 11], [2580, 804, 803, 11], [4649, 2581]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE0H9DDEf8rG"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "# print(word_index)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTrwfNOAkisV",
        "outputId": "393e786f-7497-4f92-eca3-6ce74ac3f599"
      },
      "source": [
        "# 전체 벡터 크기를 동일하게 맞춰야 함\n",
        "MAX_SEQ_LEN = 15 \n",
        "padded_seqs = preprocessing.sequence.pad_sequences(sequences, \n",
        "                                                   maxlen=MAX_SEQ_LEN, # 시퀀스의 최대 길이\n",
        "                                                   padding='post') # 빈 공간을 0으로 채우는 작업\n",
        "print(padded_seqs)                                                   "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4646  4647     0 ...     0     0     0]\n",
            " [ 4648   343   448 ...     0     0     0]\n",
            " [ 2580   803    11 ...     0     0     0]\n",
            " ...\n",
            " [13395  2517    89 ...     0     0     0]\n",
            " [  147    46    91 ...     0     0     0]\n",
            " [  555 13398     0 ...     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w52m2-aitXHF",
        "outputId": "a4a62501-cdd6-484a-d808-243556864233"
      },
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
        "ds = ds.shuffle(len(features))\n",
        "\n",
        "# train:valid:test = 7:2:1\n",
        "train_size = int(len(padded_seqs) * 0.7)\n",
        "val_size = int(len(padded_seqs) * 0.2)\n",
        "test_size = int(len(padded_seqs) * 0.1)\n",
        "\n",
        "train_ds = ds.take(train_size).batch(20)\n",
        "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
        "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
        "\n",
        "# 하이퍼파라미터\n",
        "dropout_prob = 0.5\n",
        "EMB_SIZE = 128 # 임베딩 결과로 나올 밀집 벡터 크기\n",
        "EPOCH = 5\n",
        "VOCAB_SIZE = len(word_index) + 1 # 전체 단어 수\n",
        "\n",
        "# 단어 임베딩\n",
        "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
        "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
        "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer) # 오버피팅(과적합)에 대비\n",
        "\n",
        "# 특징 추출 (특징맵)\n",
        "# 합성곱 연산\n",
        "conv1 = Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=3,\n",
        "    padding='valid',\n",
        "    activation=tf.nn.relu)(dropout_emb)\n",
        "pool1 = GlobalMaxPool1D()(conv1) # 최대 풀링 연산\n",
        "\n",
        "conv2 = Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=4,\n",
        "    padding='valid',\n",
        "    activation=tf.nn.relu)(dropout_emb)\n",
        "pool2 = GlobalMaxPool1D()(conv2)\n",
        "\n",
        "conv3 = Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=5,\n",
        "    padding='valid',\n",
        "    activation=tf.nn.relu)(dropout_emb)\n",
        "pool3 = GlobalMaxPool1D()(conv3)\n",
        "\n",
        "concat = concatenate([pool1, pool2, pool3])\n",
        "\n",
        "# 완전 연결 계층\n",
        "hidden = Dense(128, # 출력 노드 수\n",
        "               activation=tf.nn.relu)(concat)\n",
        "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
        "\n",
        "logits = Dense(3, # 3가지 클래스로 감정 분류 해야 하기 때문에\n",
        "               name='logits')(dropout_hidden)\n",
        "\n",
        "# 감정 클래스별 확률 \n",
        "predictions = Dense(3, activation=tf.nn.softmax)(logits)\n",
        "\n",
        "# CNN 모델 생성\n",
        "model = Model(inputs=input_layer, outputs=predictions)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # 손실 함수\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH\n",
        "          , verbose=1) # 진행 과정 상세히 (<-> 0:생략)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "414/414 [==============================] - 17s 38ms/step - loss: 0.9041 - accuracy: 0.5677 - val_loss: 0.6645 - val_accuracy: 0.7356\n",
            "Epoch 2/5\n",
            "414/414 [==============================] - 15s 36ms/step - loss: 0.5525 - accuracy: 0.7826 - val_loss: 0.3056 - val_accuracy: 0.9023\n",
            "Epoch 3/5\n",
            "414/414 [==============================] - 14s 35ms/step - loss: 0.3118 - accuracy: 0.8948 - val_loss: 0.1525 - val_accuracy: 0.9526\n",
            "Epoch 4/5\n",
            "414/414 [==============================] - 13s 31ms/step - loss: 0.1951 - accuracy: 0.9378 - val_loss: 0.0932 - val_accuracy: 0.9670\n",
            "Epoch 5/5\n",
            "414/414 [==============================] - 14s 33ms/step - loss: 0.1412 - accuracy: 0.9564 - val_loss: 0.0645 - val_accuracy: 0.9793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7aa4659e10>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMsYi08S0NVB",
        "outputId": "591cfdd8-4f4f-4556-db16-7f75e9487495"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60/60 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFdX9E4r8Zfr",
        "outputId": "99a18c1c-98ab-4ff5-ae6b-942c57dc7152"
      },
      "source": [
        "print('Accuracy: %f' % (accuracy * 100))\n",
        "print('loss: %f' % (loss))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.631133\n",
            "loss: 0.070869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1b8tMkI1H0Q"
      },
      "source": [
        "model.save('cnn_model.h5')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH5hLha3S2Np",
        "outputId": "ae43bdf9-37f4-4662-f413-a78b1a65d63e"
      },
      "source": [
        "test_ds = ds.take(2000).batch(20)\n",
        "\n",
        "model = load_model('cnn_model.h5')\n",
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 15, 128)      1715072     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 15, 128)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 13, 128)      49280       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 12, 128)      65664       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 11, 128)      82048       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 128)          0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 128)          0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 128)          0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 384)          0           global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          49280       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "logits (Dense)                  (None, 3)            387         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3)            12          logits[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,961,743\n",
            "Trainable params: 1,961,743\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgShJVk2S16-",
        "outputId": "9f75ece1-cf6d-404b-921d-056c331543a6"
      },
      "source": [
        "model.evaluate(test_ds, verbose=2)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 - 1s - loss: 0.0572 - accuracy: 0.9845\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.057181622833013535, 0.984499990940094]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYRfoiSBTLLE",
        "outputId": "95ac719b-3452-47c3-c7c2-4f868367e947"
      },
      "source": [
        "print('단어 시퀀스 :', corpus[10212])\n",
        "print('단어 인덱스 시퀀스 :', padded_seqs[10212])\n",
        "print('문장 분류(정답) :', labels[10212])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 시퀀스 : ['썸', '타는', '여자가', '남사친', '만나러', '간다는데', '뭐라', '해']\n",
            "단어 인덱스 시퀀스 : [   13    61   127  4320  1333 12162   856    31     0     0     0     0\n",
            "     0     0     0]\n",
            "문장 분류(정답) : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr6WH02dTpxv",
        "outputId": "b45fd941-95b5-4ec6-8cb0-45310cbad363"
      },
      "source": [
        "picks = [10212]\n",
        "predict = model.predict(padded_seqs[picks])\n",
        "predict_class = tf.math.argmax(predict, axis=1)\n",
        "print('감정 예측 점수 :', predict)\n",
        "print('감정 예측 클래스 :', predict_class.numpy())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "감정 예측 점수 : [[2.5848356e-06 2.1340316e-05 9.9997604e-01]]\n",
            "감정 예측 클래스 : [2]\n"
          ]
        }
      ]
    }
  ]
}